# Matcha-AI-DTU

Matcha-AI-DTU is a comprehensive AI-powered sports video analysis platform. It processes sports footage (specifically soccer/football), tracks the ball and players, automatically detects goals and events using SoccerNet + custom vision models, generates insightful commentary using Google Gemini LLMs, synthesizes high-quality audio voiceovers using a 3-tier neural TTS pipeline (Kokoro-82M â†’ edge-tts â†’ silence), and builds a complete analytics suite including player heatmaps, ball speed estimation, and team colour detection.

This is a **monorepo** built with Next.js, NestJS, and FastAPI, orchestrated with Docker and Turborepo.

---

## ğŸ— Architecture Overview

The system is broken down into three main applications:

```mermaid
graph TD
    subgraph "Clients"
        Web["apps/web (Next.js)"]
        Mobile["apps/mobile (Expo)"]
    end

    subgraph "Core"
        Shared["packages/shared (TS Types/API)"]
    end

    subgraph "Services"
        Orchestrator["services/orchestrator (NestJS)"]
        Inference["services/inference (FastAPI)"]
    end

    subgraph "Data"
        PG["PostgreSQL"]
        RDS["Redis"]
    end

    Web -.- Shared
    Mobile -.- Shared
    Web ==> Orchestrator
    Mobile ==> Orchestrator
    Orchestrator ==> Inference
    Orchestrator --- PG
    Orchestrator --- RDS
```

1. **[Frontend Web (apps/web)](./apps/web/README.md)**: A modern React interface built with Next.js 15. Handles video uploads, live processing status, match dashboard, and the full analytics experience.
2. **[Frontend Mobile (apps/mobile)](./apps/mobile/README.md)**: A React Native cross-platform app built with Expo and Expo Router. Shares API logic and types with the web app via a local package.
3. **[Orchestrator (services/orchestrator)](./services/orchestrator/README.md)**: A NestJS API backend. Manages state (Prisma/Postgres, Redis), WebSockets, and delegates AI tasks to the Inference service.
4. **[Shared Package (packages/shared)](./packages/shared)**: The single source of truth for TypeScript types, API client factories, and data transformation utilities used by both web and mobile.
5. **[Inference Engine (services/inference)](./services/inference/README.md)**: Python FastAPI service running YOLOv8s, ByteTrack, SoccerNet, Gemini LLM analysis, and the 3-tier TTS pipeline.

---

## âœ¨ Key Features

- **Automated Video Analysis**: Upload raw sports footage and let the system automatically analyze the content through a 5-phase AI pipeline.
- **Advanced Goal Detection**: Custom `GoalDetectionEngine` built with Kalman filtering, homography projection, and a finite state machine that auto-calibrates to the goal line, tracks the ball across frames, and confirms goals with high precision.
- **Action Event Recognition**: SoccerNet-trained model detects 11 event types: GOAL, SAVE, TACKLE, FOUL, CORNER, YELLOW_CARD, RED_CARD, PENALTY, OFFSIDE, CELEBRATION, HIGHLIGHT. Falls back to motion-peak detection when SoccerNet returns too few results.
- **AI Commentary Generation**: Context-aware, natural-sounding commentary (40â€“60 words per event) generated by Gemini 2.0 Flash, describing the on-field action with late-game intensity boosts.
- **3-Tier Neural TTS Pipeline**: 
  - ğŸ¥‡ **Kokoro-82M** (`hexgrad/Kokoro-82M`) â€” #1 ranked in TTS-Spaces-Arena, British female sports voice
  - ğŸ¥ˆ **Microsoft edge-tts** (`en-GB-RyanNeural`) â€” British male broadcaster, always available, no key needed
  - ğŸ¥‰ **FFmpeg silent audio** â€” absolute fallback
- **Real-Time Progress Tracking**: WebSocket integration provides users with live updates across the 5-phase analysis pipeline, including per-event streaming as events are detected.
- **Player Heatmap**: OpenCV-rendered top-down pitch diagram showing where each team concentrated their play throughout the entire match, with Gaussian-blurred density overlays coloured by auto-detected jersey colour.
- **Ball Speed Estimation**: YOLO ball tracking data is used to estimate the peak ball speed across the match (95th-percentile of pixel delta â†’ km/h). Displayed in the Analytics tab.
- **Team Colour Detection**: NumPy K-Means clustering on jersey crops automatically identifies which colour belongs to which team. Displayed as hex swatches.
- **Highlight Reel Generation**: Top-N non-overlapping clips are cut, overlaid with scrolling text, mixed with TTS commentary + crowd ambience + background music, and concatenated into a single MP4 via FFmpeg.
- **Context Score Intelligence**: Every event is scored 0â€“10 via a weighted formula balancing event type importance, motion intensity, temporal position, and detection confidence. Late goals are doubly weighted.

---

## ğŸš€ Quick Start Guide

### Prerequisites

| Tool | Version | Purpose |
|------|---------|---------|
| Node.js | 18+ | Frontend & Orchestrator |
| Python | 3.11+ | Inference service |
| Docker Desktop | Latest | Required for PostgreSQL & Redis containers |
| FFmpeg | Latest | Required for video processing & TTS muxing |
| NVIDIA GPU | CUDA 12.4 | Recommended for fast PyTorch/YOLO acceleration |

### 1. Launch Infrastructure
Start the database and Redis cache utilizing Docker Compose:
```bash
docker compose up -d
```
*This starts PostgreSQL on port 5433 and Redis on port 6380.*

### 2. Install Node Dependencies
Install all JavaScript dependencies seamlessly via turbo:
```bash
npm install
```
Then, deploy the database schema in the orchestrator:
```bash
cd services/orchestrator
npx prisma generate
npx prisma migrate deploy
```

### 3. Setup Python Inference Environment
The inference service requires its own Python environment with specific dependencies:
```bash
cd services/inference

# Create & activate a Python 3.11 virtual environment
py -3.11 -m venv venv
.\venv\Scripts\activate        # Windows PowerShell
# source venv/bin/activate     # Linux / macOS

# Upgrade pip
pip install --upgrade pip

# Install PyTorch with CUDA 12.4 support (if you have an NVIDIA GPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# Install the rest of the dependencies
pip install -r requirements.txt
```

### 4. Configure Environment Variables

**`services/orchestrator/.env`** (create this file):
```env
DATABASE_URL="postgresql://matcha_user:matcha_password@localhost:5433/matcha_db?schema=public"
HF_TOKEN=hf_your_huggingface_token_here
CORS_ORIGIN=http://localhost:3000
INFERENCE_URL=http://localhost:8000
PORT=4000
```

**`services/inference/.env`** (create this file):
```env
GEMINI_API_KEY=your_google_ai_studio_api_key
HF_TOKEN=hf_your_huggingface_token_here
ORCHESTRATOR_URL=http://localhost:4000
```

> ğŸ”‘ Get a free Gemini API key at [Google AI Studio](https://makersuite.google.com/app/apikey).  
> ğŸ”‘ Get a free HuggingFace token at [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) â€” select "Read" scope.  
> The `HF_TOKEN` is optional but highly recommended â€” without it, Kokoro-82M TTS runs at anonymous rate limits.

### 5. Start All Services (Recommended â€” Turborepo)
```bash
# From the monorepo root â€” starts all three services together
npx turbo run dev
```

Alternatively, run each service manually in separate terminals:

**Terminal 1 â€” Orchestrator (Port 4000)**
```bash
cd services/orchestrator
npm run start:dev
```

**Terminal 2 â€” Inference Engine (Port 8000)**
```bash
cd services/inference
.\venv\Scripts\activate
uvicorn main:app --host 0.0.0.0 --port 8000
```

**Terminal 3 â€” Frontend Web App (Port 3000)**
```bash
cd apps/web
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

---

## ğŸ›  Project Structure

```text
Matcha-AI-DTU/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/                # Next.js 15 Web App
â”‚   â””â”€â”€ mobile/             # Expo (React Native) Mobile App
â”œâ”€â”€ packages/
â”‚   â””â”€â”€ shared/             # @matcha/shared â€” Types, Client, Utils
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ orchestrator/       # NestJS API (Port 4000)
â”‚   â”‚   â””â”€â”€ prisma/         # Database schema & migrations
â”‚   â””â”€â”€ inference/          # Python FastAPI AI Pipeline (Port 8000)
â”‚       â”œâ”€â”€ app/core/       # Pipeline modules (analysis, heatmap, goal detection)
â”‚       â””â”€â”€ AI_PIPELINE.md  # Detailed 5-phase pipeline documentation
â”œâ”€â”€ uploads/                # Global video/audio/heatmap assets (shared)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md     # Full system architecture
â”‚   â”œâ”€â”€ API_REFERENCE.md    # HTTP & WebSocket API contracts
â”‚   â””â”€â”€ CONTRIBUTING.md     # Contribution guidelines & dev setup
â””â”€â”€ docker-compose.yml      # PostgreSQL & Redis infrastructure
```

---

## ğŸ“š Documentation

| Document | Description |
|---|---|
| [docs/ARCHITECTURE.md](./docs/ARCHITECTURE.md) | Full system architecture â€” data flow, DB schema, analytics pipeline, TTS tiers, frontend tree, env var reference |
| [docs/API_REFERENCE.md](./docs/API_REFERENCE.md) | Complete HTTP + WebSocket API contracts with request/response bodies, event type table, and score formula |
| [docs/CONTRIBUTING.md](./docs/CONTRIBUTING.md) | Contributing guidelines, local dev setup, adding new features, mobile responsiveness guide |
| [services/inference/AI_PIPELINE.md](./services/inference/AI_PIPELINE.md) | Deep-dive into all 5 pipeline phases: YOLO, SoccerNet, Gemini, TTS, and analytics |

---

## ğŸ’¡ Troubleshooting

- **Ports already in use**: Use `netstat -ano | Select-String ":3000"` to find and kill conflicting operations.
- **Postgres/Redis connection failures**: Ensure Docker daemon is running and containers haven't exited (`docker ps -a`).
- **Python Import errors (TTS/Torch)**: Double-check that your `venv` is activated. Run `pip install -r requirements.txt` again.
- **Analysis stuck at 0%**: Ensure `ORCHESTRATOR_URL` is correct in the Inference `.env`. The callback route may be unreachable. Check the Python terminal for error logs.
- **Kokoro TTS not working**: Set `HF_TOKEN` in `services/inference/.env`. Without it, anonymous HuggingFace rate limits may block Kokoro â€” the system will automatically fall back to `edge-tts`.
- **Heatmap not showing in Analytics tab**: The heatmap is only generated if YOLO detected players during the analysis. Re-analyze the match. Check the inference logs for `Heatmap saved â†’` or `Heatmap generation failed:`.
- **`prisma generate` fails with EPERM**: This means the orchestrator is running and has the Prisma DLL locked. Stop the service, run `npx prisma generate`, then restart.

---

*Built for Matcha-AI-DTU* ğŸ†
